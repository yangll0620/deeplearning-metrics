## Brief Description

Cohen's kappa coefficient (κ) is a statistic which measures inter-rater agreement for qualitative (categorical) items. It is generally thought to be a more robust measure than simple percent agreement calculation, as κ takes into account the possibility of the agreement occurring by chance. (From Wikepedia)

## Definition

<img src="https://latex.codecogs.com/svg.latex?\Large&space; k=\frac{p_0 - p_e}{1- p_e}" title="\Large x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}" />

